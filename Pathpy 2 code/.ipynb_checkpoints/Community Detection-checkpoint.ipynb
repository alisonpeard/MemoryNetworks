{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "further-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import pathpy as pp\n",
    "import my_functions\n",
    "from my_functions import matprint\n",
    "import igraph\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "\n",
    "from IPython.display import * # no idea what this does\n",
    "from IPython.display import HTML # no idea what this does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-baltimore",
   "metadata": {},
   "source": [
    "# Community detection\n",
    "## Following Rosvall (2014) paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "diagnostic-waste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-03 17:55:05 [Severity.INFO]\tReading ngram data ... \n",
      "2021-04-03 17:55:05 [Severity.INFO]\tfinished. Read 358 paths with maximum length 6\n",
      "2021-04-03 17:55:05 [Severity.INFO]\tCalculating sub path statistics ... \n",
      "2021-04-03 17:55:05 [Severity.INFO]\tfinished.\n"
     ]
    }
   ],
   "source": [
    "# from paths dataset - 1% sample to start\n",
    "flight_paths = pp.Paths.read_file(\"Data/US flights 2011/US flights od.ngram\", separator=',', frequency=True)\n",
    "m1 = pp.Network.from_paths(flight_paths)\n",
    "m2 = pp.HigherOrderNetwork(flight_paths,k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-ladder",
   "metadata": {},
   "source": [
    "## Functions\n",
    "    pathpy.algorithms.infomap + \n",
    "    find_communities_sa(obj, iterations=100, initial_map=None, T=0.1, t_i=1) \n",
    "Only works for undirected, unweighted networks <br>\n",
    "Gives funny results for flight_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suited-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pp.algorithms.infomap.find_communities_sa(m1)\n",
    "#pp.algorithms.infomap.find_communities_sa(flight_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-width",
   "metadata": {},
   "source": [
    "# Core-periphery for $\\mathcal{M}_1$ network\n",
    "1. Start at the node with the minimum total node strength $s^{in}_i+s^{out}_i$ and set $S=v_i$\n",
    "2. Add a node to $S$ such that it creates the smallest increase in persistence probability \\begin{equation}\n",
    "\\alpha_S = \\frac{\\sum_{i,j \\in S}p_i^*T_{ij} }{\\sum_{i \\in S}p_i^*}\n",
    "\\end{equation}\n",
    "3. Then the $\\alpha$-periphery is the set of nodes $S_{\\alpha}$ satisfying $\\alpha_i \\leq \\alpha$ and you can tune by $\\alpha$\n",
    "Choose uniformly if you get have multiple nodes with the same strength etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "Start at "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
